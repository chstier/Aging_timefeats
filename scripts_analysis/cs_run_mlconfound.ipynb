{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlconfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlconfound.stats import partial_confound_test\n",
    "from mlconfound.simulate import simulate_y_c_yhat\n",
    "from mlconfound.plot import plot_null_dist, plot_graph\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify home directory\n",
    "def get_home_directory_with_expanduser():\n",
    "    return os.path.expanduser(\"~\")\n",
    "\n",
    "# read in demographics of the subjects\n",
    "demo = pd.read_csv(\"~/sciebo/Features_age/data/demo_regular.csv\", sep=';')\n",
    "print(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in PLS-results for the conventional features\n",
    "from scipy.io import loadmat\n",
    "\n",
    "res = loadmat(\"/Users/Christina/sciebo/Features_age/data/pls_av_full_10k_5c_hctsa_r50_stratf.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = demo['real_age'].to_numpy()\n",
    "#print(y)\n",
    "sex = demo['sex'].to_numpy()\n",
    "eTIV = demo['eTIV'].to_numpy()\n",
    "#print(eTIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a couple of variables\n",
    "type(res)\n",
    "# type(demo)\n",
    "# print(demo.real_age)\n",
    "res.keys() # this will show you the var name of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res[\"av_yhat\"]\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = len(data[1])\n",
    "print(num_columns)\n",
    "#column = data[:, 0]\n",
    "#print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over features and run partial confound test for variable of interest and store results\n",
    "# decide on the number of permutations!\n",
    "import numpy as np\n",
    "result = []\n",
    "graphs = []\n",
    "distr = []\n",
    "\n",
    "# change variable of interest accordingly\n",
    "for i in range(num_columns):\n",
    "    y_hat = data[:, i]\n",
    "    \n",
    "    # The random seed is set for reproducible results. The flag return_null_dist is set so that the full permutation-based null distribution is returned, e.g. for plotting purposes.\n",
    "   # ret=partial_confound_test(y, y_hat, sex, return_null_dist=True,num_perms=1000,\n",
    "    #              random_state=42)\n",
    "    \n",
    "    ret=partial_confound_test(y, y_hat, eTIV, return_null_dist=True,num_perms=1000,\n",
    "                  random_state=42)\n",
    "\n",
    "    #p = plot_null_dist(ret)\n",
    "    #pp = plot_graph(ret, y_name='age', yhat_name='predicted age', c_name='sex', outfile_base='example')\n",
    "    \n",
    "    result.append(ret)\n",
    "    #graphs.append(pp)\n",
    "    #distr.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only main parameters and save as dataframe\n",
    "type(result)\n",
    "\n",
    "# Create an empty list to store the data for each row\n",
    "rows = []\n",
    "\n",
    "# Iterate over the list\n",
    "for i in range(0, len(result)):\n",
    "    r2_y_c = result[i][0]\n",
    "    r2_y_yhat = result[i][1]\n",
    "    r2_yhat_c = result[i][2]\n",
    "    expected_r2_yhat_c = result[i][3]\n",
    "    p_ci_low = result[i][5][0]\n",
    "    p_ci_high = result[i][5][1]\n",
    "    p = result[i][4]\n",
    "    \n",
    "    row = [r2_y_c, r2_y_yhat, r2_yhat_c,expected_r2_yhat_c, p_ci_low, p_ci_high, p]\n",
    "    rows.append(row)\n",
    "    \n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(rows, columns=['r2_y_c', 'r2_y_yhat', 'r2_yhat_c', 'expected_r2_yhat_c', 'p_ci_low', 'p_ci_high', 'p'])\n",
    "\n",
    "# Set values equal to 0 to NaN\n",
    "df['p'] = df['p'].replace(0, np.nan)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perform fdr corrections on the p-values\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Filter out NaN p-values\n",
    "filtered_pvalues = df['p'].dropna()\n",
    "\n",
    "# Perform FDR correction on the filtered p-values\n",
    "rejected, corrected_pvalues, _, _ = multipletests(filtered_pvalues, method='fdr_bh')\n",
    "\n",
    "# Create a new DataFrame with corrected p-values\n",
    "df_corrected = pd.DataFrame({'p_fdr': corrected_pvalues}, index=filtered_pvalues.index)\n",
    "\n",
    "# Merge the corrected p-values back to the original DataFrame\n",
    "df['p_fdr'] = np.nan  # Initialize with NaN\n",
    "df.loc[~df['p'].isna(), 'p_fdr'] = df_corrected['p_fdr']\n",
    "\n",
    "# Print the DataFrame with corrected p-values\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to an Excel file\n",
    "df.to_excel(\"~/sciebo/Features_age/results_all_subjects/confound_strf/confound_eTIV_hctsa2_r50_stratf.xlsx\", index=False)\n",
    "#df.to_excel(\"~/sciebo/Features_age/results_all_subjects/confound_strf/confound_sex_hctsa2_r50_stratf.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### let's plot some results\n",
    "##### try with AC=11, which is index = 95 (remember that Python starts counting with 0, not one)\n",
    "##### try with center of gravity, which is index = 5980\n",
    "\n",
    "i = 5980\n",
    "# loop over features and run partial confound test for sex and store results\n",
    "# decide on the number of permutations!\n",
    "result = []\n",
    "graphs = []\n",
    "distr = []\n",
    "\n",
    "#for i in range(num_columns):\n",
    "y_hat = data[:, i]\n",
    "    \n",
    "# The random seed is set for reproducible results. The flag return_null_dist is set so that the full permutation-based null distribution is returned, e.g. for plotting purposes.\n",
    "ret=partial_confound_test(y, y_hat, eTIV, return_null_dist=True,num_perms=1000,random_state=42)\n",
    "\n",
    "p = plot_null_dist(ret)\n",
    "pp = plot_graph(ret, y_name='age', yhat_name='predicted age', c_name='eTIV', outfile_base='example')\n",
    "    \n",
    "    #result.append(ret)\n",
    "    #graphs.append(pp)\n",
    "    #distr.append(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aging_feat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
